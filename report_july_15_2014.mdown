![Alt text](http://rrezarta-krasniqi.github.io/esquared.jpg) 
<hr>
##### :date: July 15, 2014 


The Google Dataset of Testing Results
=====================
Data Download and Preprocessing
-------------------------------
~~~bash
git clone https://code.google.com/p/google-shared-dataset-of-test-suite-results/
cd google-shared-dataset-of-test-suite-results/posted
gunzip testShareData.csv.rev.gz
sed -i '' 's/^,//g' testShareData.csv.rev # replace the "," with "" if it is in the beginning of the line
sed -i '' '$ d' testShareData.csv.rev # removes the last line which is empty
~~~

MySQL Database Schema and Import CSV File
-----------------------------------------

:small_red_triangle_down: **Query Implementation:**

~~~mysql
CREATE TABLE `google_dataset` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `test_suite_mapped_id` varchar(255) DEFAULT NULL,
  `test_suite` longtext,
  `change_request` int(11) DEFAULT NULL,
  `stage` varchar(255) DEFAULT NULL,
  `test_status` varchar(255) DEFAULT NULL,
  `launch_time` datetime DEFAULT NULL,
  `execution_time` int(11) DEFAULT NULL,
  `test_size` varchar(255) DEFAULT NULL,
  `shard_number` int(11) DEFAULT NULL,
  `run_number` int(11) DEFAULT NULL,
  `test_language` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `change_request_idx` (`change_request`) USING BTREE,
  KEY `shard_number_idx` (`shard_number`) USING BTREE,
  KEY `stage_idx` (`stage`) USING BTREE,
  KEY `test_status_idx` (`test_status`) USING BTREE,
  KEY `test_language_idx` (`test_language`) USING BTREE,
  KEY `test_size_idx` (`test_size`) USING BTREE,
  KEY `test_suite_mapped_id_idx` (`test_suite_mapped_id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=3468949 DEFAULT CHARSET=utf8;

LOAD DATA INFILE '/path/to/testShareData.csv.rev' INTO TABLE google_dataset \
FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' \
(id, change_request, execution_time, launch_time, run_number, shard_number, stage, test_language, test_size, test_status, test_suite, test_suite_mapped_id);

-- Query OK, 3468948 rows affected (1 min 34.64 sec)
-- Records: 3468948  Deleted: 0  Skipped: 0  Warnings: 0

CREATE INDEX test_suite_mapped_id_idx ON google_dataset (test_suite_mapped_id) USING BTREE;
CREATE INDEX change_request_idx ON google_dataset (change_request) USING BTREE;
CREATE INDEX shard_number_idx ON google_dataset (shard_number) USING BTREE;
CREATE INDEX stage_idx ON google_dataset (stage) USING BTREE;
CREATE INDEX test_size_idx ON google_dataset (test_size) USING BTREE;
CREATE INDEX test_status_idx ON google_dataset (test_status) USING BTREE;
CREATE INDEX test_language_idx ON google_dataset (test_language) USING BTREE;
~~~


Dataset Analysis
-------------

* Total Distinct Test_Suites are: **5555**

:small_red_triangle_down: **Query Implementation:**

~~~ mysql
        SELECT COUNT(DISTINCT test_suite_mapped_id) AS distinct_test_suits 
        FROM google_dataset;
~~~

<br/>

* There are also **3468948** records in the entire dataset

:small_red_triangle_down: **Query Implementation:**
~~~ mysql

        SELECT COUNT(*) total_records FROM google_dataset;
~~~

<br/>

* There are total of **169** different TEST_SUITES with partitioned executions

:small_red_triangle_down: **MySQL Implementation:**

~~~ mysql

        SELECT COUNT(DISTINCT test_suite) AS test_suites
        FROM   google_dataset
        WHERE  shard_number IN (SELECT shard_number
                                FROM   google_dataset
                                WHERE  shard_number > 1);
~~~

<br/>


* There are total of **4520** different change request during ECT Phase
* There are total of **1693** different change request during ICT Phase

:small_red_triangle_down: **MySQL Implementation:**

~~~mysql
SELECT Count(*) AS total_change_requests, stage
 FROM (SELECT Count(change_request) AS change_request_count, IF(stage="POST", "ECT phase",stage) AS phase
        FROM  google_dataset d
        WHERE 1 = 1
          AND stage = "POST"
     GROUP BY change_request) AS T
UNION ALL
SELECT Count(*) AS total_change_requests,
       stage
  FROM (SELECT Count(change_request) AS change_request_count, IF(stage="PRES", "ICT phase",stage) AS phase
          FROM google_datasetT d
         WHERE 1 = 1
           AND stage = "PRES"
      GROUP BY change_request) AS T
~~~

:small_red_triangle_down: **Query Results:**

| total_change_requests | phase      |
|-----------------------|:----------:|
| 4520                  |  ECT phase |
| 1693                  |  ICT phase |


<br>

* Total Test Suite Executions Categorized By Stage:
  * There are total of **2037183** test executions in the  ECT Phase 
  * There are total of **1431765** test executions in the ICT Phase 

:small_red_triangle_down: **MySQL Implementation:**

~~~mysql
SELECT COUNT(test_suite_name) AS test_suite_executions, 
(CASE WHEN stage = 'POST' THEN 'ECT phase'
      WHEN stage = 'PRES' THEN 'ICT phase'
      ELSE stage 
END) AS phase
FROM google_dataset
WHERE stage IN ('POST', 'PRES')
GROUP BY stage
~~~


:small_red_triangle_down: **Query Results:**

| test_suite_executions | phase      |
|-----------------------|:----------:|
| 2037183               |  ECT phase |
| 1431765               |  ICT phase |


<br>


* There are **154** distinct test executions that fail during the **POST** phase,
  containing **6878** change requests

:small_red_triangle_down: **MySQL Implementation:**

~~~mysql
SELECT DISTINCT COUNT(DISTINCT test_suite_mapped_id) total_test_suites,
  count(change_request) AS tot_change_requests,
  test_status,
  stage AS phase 
FROM google_dataset 
WHERE test_status = "FAILED" 
AND stage = "POST"; 
~~~

:small_red_triangle_down: **Query Results:**

| total_test_suites | total_change_requests | test_status | phase |
|:-----------------:|:---------------------:|:-----------:|:-----:|
|        154        |          6878         |    FAILED   |  POST |


<br>

* From **6878** change requests, only  **1045** are unique ones

:small_red_triangle_down: **MySQL Implementation:**

~~~mysql
SELECT COUNT(DISTINCT change_request) AS distinct_change_requests,
test_status,
stage AS phase
FROM google_dataset 
WHERE test_status = "FAILED" 
AND stage = "POST";
~~~

:small_red_triangle_down: **Query Results:**

| distinct_change_requests | test_status | phase |
|:------------------------:|:-----------:|:-----:|
|           1045           |    FAILED   |  POST |


<br>

<hr>
* Categorization by **Language** (categorize_by_lang.py)
<hr>

:small_red_triangle_down: **Pyhton Implementation:**

~~~python
import pymysql
import pdb

conn = pymysql.connect(host='cse.unl.edu', port=3306, user='rkrasniq', passwd='******', db='rkrasniq')
iterator = conn.cursor()
iterator.execute("SELECT * FROM google_dataset WHERE stage = 'POST' GROUP BY test_language") 

records = []

for row in iterator:
  records.append(row)

iterator.close()

for record in records:
  test_language = record[11]


  lang_cursor = conn.cursor() 
  lang_cursor.execute("SELECT * FROM google_dataset WHERE stage = 'POST' AND test_language = '%s'" % test_language)

  recs = []
  for row in lang_cursor:
    recs.append(row) 

  total_failure = float(len(filter(lambda x: x[5] == "FAILED", recs)))
  total_records = float(len(recs))

  if total_failure != 0:
    avg_exec_time = reduce(lambda x, y: x + y, map(lambda z: float(z[7]), recs)) / float(len(recs))
  else:
    avg_exec_time = 0 

      if total_failure > 0:
      print test_language + "\t" \
         + str(total_failure) + "\t" \
         + str((avg_exec_time/1000)%60) + "\t" \
         + str((100.0 * total_failure) / total_records) 
  lang_cursor.close()

conn.close()  
~~~


* Graph: Categorization By **Language** (data_categorization.xsls)

:small_red_triangle_down: **Python Results:**

![Alt text](http://rrezarta-krasniqi.github.io/lang.jpg)


*Also the SQL version (with some modifications):**

~~~mysql
SELECT
        test_language as language,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) = "SMALL") AS small,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) = "MEDIUM") AS medium,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) = "LARGE") AS large,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) IN ("SMALL","MEDIUM","LARGE")) AS total_failure,
        AVG((((execution_time % (1000*60*60)) % (1000*60)) / 1000)) AS avg_execution_time_sec,
        TRUNCATE(SUM(IF(UPPER(test_status) = "FAILED",1,0))*100/((SUM(IF(UPPER(test_status) = "FAILED",1,0)) + SUM(IF(UPPER(test_status) = "PASSED",1,0)))), 2) AS rate_failure
FROM google_dataset
         WHERE UPPER(stage) = "POST"
GROUP BY test_language
HAVING rate_failure > 0
ORDER BY rate_failure DESC;
~~~

<br>


<hr>
* Categorization by **Language and Size** (categorize_by_lang_and_size.py)
<hr>

:small_red_triangle_down: **Python Implementation:**

~~~python
import pymysql
import pdb

conn = pymysql.connect(host='cse.unl.edu', port=3306, user='rkrasniq', passwd='******', db='rkrasniq')
iterator = conn.cursor()
iterator.execute("SELECT * FROM google_dataset WHERE stage = 'POST' GROUP BY test_language, test_size") 

records = []
for row in iterator:

  records.append(row)

iterator.close()

for record in records:
  test_language = record[11]
  test_size = record[8]

  lang_cursor = conn.cursor() 
  lang_cursor.execute("SELECT * FROM google_dataset WHERE test_language = '%s' AND test_size = '%s' AND stage = 'POST'" % (test_language, test_size))

  recs = []
  for row in lang_cursor:
    recs.append(row) 

  total_failure = float(len(filter(lambda x: x[5] == "FAILED", recs)))
  total_records = float(len(recs))

  if total_failure != 0:
    avg_exec_time = reduce(lambda x, y: x + y, map(lambda z: float(z[7]), recs)) / float(len(recs))
  else:
    avg_exec_time = 0 

  if total_failure > 0:
    print test_language + "\t" \
       + test_size + "\t" \
         + str(total_failure) + "\t" \
         + str((avg_exec_time/1000)%60) + "\t" \
         + str((100.0 * total_failure) / total_records) 
  lang_cursor.close()

conn.close()  
~~~

**Also the SQL version (with some modifications):**

~~~mysql
SELECT 
        test_language,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) = "SMALL") AS small,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) = "MEDIUM") AS medium,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) = "LARGE") AS large,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) IN ("SMALL","MEDIUM","LARGE")) AS total_failure,
        AVG((((execution_time % (1000*60*60)) % (1000*60)) / 1000)) AS avg_execution_time_sec,
        TRUNCATE(SUM(IF(UPPER(test_status) = "FAILED",1,0))*100/((SUM(IF(UPPER(test_status) = "FAILED",1,0)) + SUM(IF(UPPER(test_status) = "PASSED",1,0)))), 2) AS rate_failure
FROM google_dataset
         WHERE stage = "POST"
Group By test_language, test_size
HAVING rate_failure > 0
ORDER BY rate_failure DESC;
~~~


:small_red_triangle_down: **Python Results:**

![Alt text](http://rrezarta-krasniqi.github.io/lang_and_size.jpg)

<br>

<hr>
* Categorization by **Language Size and Stage** (categorize_by_lang_size_and_stage.py)
<hr>

:small_red_triangle_down: **Python Implementation:**

~~~python
import pymysql
import pdb

conn = pymysql.connect(host='cse.unl.edu', port=3306, user='rkrasniq', passwd='ob8{i5', db='rkrasniq')
iterator = conn.cursor()
iterator.execute("SELECT * FROM google_dataset GROUP BY test_language, test_size, stage") 

records = []

for row in iterator:
  records.append(row)

iterator.close()

for record in records:
  test_language = record[11]
  test_size = record[8]
  stage = record[4]

  lang_cursor = conn.cursor() 
  lang_cursor.execute("SELECT * FROM google_dataset WHERE test_language = '%s' AND test_size = '%s' AND stage = '%s'" % (test_language, test_size, stage))

  recs = []
  for row in lang_cursor:
    recs.append(row) 

  total_failure = float(len(filter(lambda x: x[5] == "FAILED", recs)))
  total_records = float(len(recs))

  if total_failure != 0:
    avg_exec_time = reduce(lambda x, y: x + y, map(lambda z: float(z[7]), recs)) / float(len(recs))
  else:
    avg_exec_time = 0

  if total_failure > 0:
             print test_language + "\t" \
                 + test_size + "\t" \
                 + stage + "\t" \
                 + str(total_failure) + "\t" \
                 + str((avg_exec_time/1000)%60) + "\t" \
                 + str((100.0 * total_failure) / total_records) 
  lang_cursor.close()

conn.close()  
~~~

<br>

*Also the SQL version (with some modifications):**

~~~mysql
SELECT 
        test_language,
        test_size
        stage,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) = "SMALL") AS small,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) = "MEDIUM") AS medium,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) = "LARGE") AS large,
        SUM(IF(test_status = "FAILED",1,0) AND UPPER(test_size) IN ("SMALL","MEDIUM","LARGE")) AS total_failure,
        AVG((((execution_time % (1000*60*60)) % (1000*60)) / 1000)) AS avg_execution_time_sec,
        TRUNCATE(SUM(IF(UPPER(test_status) = "FAILED",1,0))*100/((SUM(IF(UPPER(test_status) = "FAILED",1,0)) + SUM(IF(UPPER(test_status) = "PASSED",1,0)))), 2) AS rate_failure
FROM google_dataset
         WHERE stage IN ("POST", "PRES")
Group By test_language, test_size, stage
HAVING rate_failure > 0
ORDER BY rate_failure DESC
~~~


* Graph: Categorization By **Language, Size and Stage** (data_categorization.xsls)

![Alt text](http://rrezarta-krasniqi.github.io/lang_size_and_stage_graph.jpg)


:small_red_triangle_down: **Python Results:**

![Alt text](http://rrezarta-krasniqi.github.io/lang_size_and_stage_results.jpg)


<br>

<hr>
Flow of Google Data Grouped By **Change Requests Per Day** (change_request_day.sql)
<hr>


:small_red_triangle_down: **MySQL Implementation:**
~~~MySQL
SELECT change_request, 
       DAY(launch_time) AS day,
       tot_runs_per_day,
       AVG((((execution_time % (1000*60*60)) % (1000*60)) / 1000)) AS avg_execution_time_sec,
       SUM(failed*100.0)/tot_runs_per_day AS rate_failure
FROM
(
    SELECT change_request,
           launch_time,
           COUNT(launch_time) AS tot_runs_per_day,
           execution_time,
           SUM(IF(test_status="FAILED",1,0)) AS failed,
           SUM(IF(test_status="PASSED",1,0)) AS passed
    FROM google_dataset d
    GROUP BY change_request, DAY(launch_time)
) AS T
GROUP BY change_request, day
HAVING rate_failure > 0;
~~~

* Graph: Categorization By **Change Request Per Day** (change_request_day.xsls)


* **First Graph Representation**

![Alt text](http://rrezarta-krasniqi.github.io/change_req_per_day_1.jpg)


* **Second Graph Representation**

![Alt text](http://rrezarta-krasniqi.github.io/change_req_per_day_2.jpg)


* **Third Graph Representation**

![Alt text](http://rrezarta-krasniqi.github.io/change_req_per_day_3.jpg)


<br>

<hr>
Flow of Google Data Grouped By **Total Test Execution Per Day** (total_test_executions_per_day.sql)
<hr>


:small_red_triangle_down: **MySQL Implementation:**
~~~MySQL
SELECT test_suite_mapped_id,
       DAY(launch_time) AS day,
       tot_runs_per_day,
       AVG((((execution_time % (1000*60*60)) % (1000*60)) / 1000)) AS avg_execution_time_sec,
       SUM(failed*100.0)/tot_runs_per_day AS rate_failure
FROM
(
    SELECT test_suite_mapped_id,
           launch_time,
           COUNT(launch_time) AS tot_runs_per_day,
           execution_time,
           SUM(IF(test_status="FAILED",1,0)) AS failed,
           SUM(IF(test_status="PASSED",1,0)) AS passed
    FROM google_dataset d
    GROUP BY test_suite_mapped_id, DAY(launch_time)
) AS T
GROUP BY test_suite_mapped_id, day
HAVING rate_failure > 0;
~~~

* Graph: Categorization By **Test Suite Execution Per Daye** (total_test_executions_per_day.xsls)


* **First Graph Representation**

![Alt text](http://rrezarta-krasniqi.github.io/test_exec_per_day_1.jpg)


* **Second Graph Representation**

![Alt text](http://rrezarta-krasniqi.github.io/test_exec_per_day_2.jpg)


<br>


<hr>
Unique Failing Test Suites (Executions) During ECT Phase (unique_faling_test_suites_post_pre.sql)
<hr>


:bulb: **NOTE:**
   * Change requests that belong to each test_suite can be more than
     one and they in some cases are repetitive or distinct

:bulb: **Explanation:**

*For example:*

  * failure rate - 72/84 -- means for T5273, there are 72 different change requests that fail from 84, 
    they are then grouped by stage and size
  
  * failure rate - 69/81 -- means for T5273, there are 69 different change requests that fail from 81,
    they are then grouped by stage and size


:small_red_triangle_down: **MySQL Implementation:**

~~~MySql
SELECT test_suite_mapped_id,
       tot_change_requests, 
       stage,
       test_language,
       test_size,
       "failed",
       launch_time,
       avg_execution_time_sec,
       rate_failure
FROM
(
      SELECT DISTINCT test_suite_mapped_id,
               COUNT(change_request) as tot_change_requests,
               stage,
               test_language,
               test_size,
               "failed",
               test_status,
               DATE_FORMAT(launch_time, '%a, %D, %M') AS launch_time,
               AVG((((execution_time % (1000*60*60)) % (1000*60))/1000)) AS avg_execution_time_sec,
               TRUNCATE(SUM(IF(UPPER(test_status) = "FAILED",1,0)*100)/((SUM(IF(UPPER(test_status) = "FAILED",1,0)) + SUM(IF(UPPER(test_status) = "PASSED",1,0)))), 2) AS rate_failure
         FROM google_dataset
        WHERE UPPER(stage) ="POST"
    GROUP BY test_suite_mapped_id, stage, test_size
     UNION ALL
     SELECT DISTINCT test_suite_mapped_id,
               count(change_request) as tot_change_requests,
               stage,
               test_language,
               test_size,
               "failed",
               test_status,
               DATE_FORMAT(launch_time, '%a, %D, %M') AS launch_time,
               AVG((((execution_time % (1000*60*60)) % (1000*60))/1000)) AS avg_execution_time_sec,
               TRUNCATE(SUM(IF(UPPER(test_status) = "FAILED",1,0)*100)/((SUM(IF(UPPER(test_status) = "FAILED",1,0)) + SUM(IF(UPPER(test_status) = "PASSED",1,0)))), 2) AS rate_failure
         FROM google_dataset
        WHERE UPPER(stage) ="PRES"
  GROUP BY test_suite_mapped_id, stage, test_size
) AS T
HAVING rate_failure <> 0
 ORDER BY stage, rate_failure DESC
~~~


* Graph: Unique Test Suite Failures During ICT & ECT Phase (unique_test_suite_failures_post_pre.xsls)


![Alt text](http://rrezarta-krasniqi.github.io/unique_failing_test_suites_post_pre.jpg)


![Alt text](http://rrezarta-krasniqi.github.io/unique_failing_test_suites_post_pre_2d.jpg)


![Alt text](http://rrezarta-krasniqi.github.io/unique_failing_test_suites_post_pre_3d.jpg)


:small_red_triangle_down: **MySQL Results:**


Refer to excel sheet to chekc the results the results

<br>

<hr>
Unique Test Suite Failures During ECT Phase Only (unique_faling_test_suites_post.sql)
<hr>


:bulb: **NOTE:**
   * Change requests that belong to each test_suite can be more than
     one and they in some cases are repetitive or distinct


:small_red_triangle_down: **MySQL Implementation:**

~~~MySql
SELECT test_suite_mapped_id,
       tot_change_requests, 
       stage,
       test_language,
       test_size,
       "failed",
       launch_time,
       avg_execution_time_sec,
       rate_failure
FROM
(
      SELECT DISTINCT test_suite_mapped_id,
               COUNT(change_request) as tot_change_requests,
               stage,
               test_language,
               test_size,
               "failed",
               test_status,
               DATE_FORMAT(launch_time, '%a, %D, %M') AS launch_time,
               AVG((((execution_time % (1000*60*60)) % (1000*60))/1000)) AS avg_execution_time_sec,
               TRUNCATE(SUM(IF(UPPER(test_status) = "FAILED",1,0)*100)/((SUM(IF(UPPER(test_status) = "FAILED",1,0)) + SUM(IF(UPPER(test_status) = "PASSED",1,0)))), 2) AS rate_failure
         FROM google_dataset
        WHERE UPPER(stage) ="POST"
    GROUP BY test_suite_mapped_id, stage, test_size
) AS T
HAVING rate_failure <> 0
 ORDER BY stage, rate_failure DESC
~~~


* Graph: Unique Test Suite Failures During POST Phase (unique_test_suite_failures_post.xsls)


* **First Graph Representation**

![Alt text](http://rrezarta-krasniqi.github.io/unique_failing_test_suites_post.jpg)


**Second Graph Representation**

![Alt text](http://rrezarta-krasniqi.github.io/unique_failing_test_suites_post_2d.jpg)


**Third Graph Representation**

![Alt text](http://rrezarta-krasniqi.github.io/unique_failing_test_suites_post_3d.jpg)


:small_red_triangle_down: **MySQL Results:**


Refer to excel sheet to check the results

<br>

<hr>
Total Unique Failing Test Suites (executions) (unique_tot_faling_test_suites.sql)
<hr>

:bulb: **NOTE:**
 * There are total of 358 unique test suites for both stages.
 * **153** are unique test suites failing from POST stage that contain total of **285,105** change requests
 * **205** are unique test suites failing from PRES stage that contain total of **115,745** change requests


:small_red_triangle_down: **MySQL Implementation:**

~~~MySQL
SELECT  COUNT(CASE WHEN stage = "PRES" THEN 1
             WHEN stage = "POST" THEN 1
             ELSE stage END) AS tot_faling_test_suites, 
             stage AS phase
FROM
(
     SELECT DISTINCT test_suite_mapped_id,
               COUNT(change_request) as tot_change_requests,
               stage,
               test_language,
               test_size,
               "failed",
               test_status,
               DATE_FORMAT(launch_time, '%a, %D, %M') AS launch_time,
               AVG((((execution_time % (1000*60*60)) % (1000*60))/1000)) AS avg_execution_time_sec,
               TRUNCATE(SUM(IF(UPPER(test_status) = "FAILED",1,0)*100)/((SUM(IF(UPPER(test_status) = "FAILED",1,0)) + SUM(IF(UPPER(test_status) = "PASSED",1,0)))), 2) AS rate_failure
         FROM google_dataset
        WHERE UPPER(stage) ="POST"
    GROUP BY test_suite_mapped_id, stage, test_size
HAVING rate_failure > 0
UNION ALL
      SELECT DISTINCT test_suite_mapped_id,
               count(change_request) as tot_change_requests,
               stage,
               test_language,
               test_size,
               "failed",
               test_status,
               DATE_FORMAT(launch_time, '%a, %D, %M') AS launch_time,
               AVG((((execution_time % (1000*60*60)) % (1000*60))/1000)) AS avg_execution_time_sec,
               TRUNCATE(SUM(IF(UPPER(test_status) = "FAILED",1,0)*100)/((SUM(IF(UPPER(test_status) = "FAILED",1,0)) + SUM(IF(UPPER(test_status) = "PASSED",1,0)))), 2) AS rate_failure
         FROM google_dataset
        WHERE UPPER(stage) ="PRES"
  GROUP BY test_suite_mapped_id, stage, test_size
HAVING rate_failure > 0
) AS T
GROUP BY stage
~~~

<br>

:small_red_triangle_down: **MySQL Results:**

| tot_failing_test_suites | phase |
|:-----------------------:|:-----:|
|           153           |  POST |
|           205           |  PRES |


### Some More Statistics About The Data Overall


| total unique test suites | total_faling unique test suites | rate failure % |
|:------------------------:|:-------------------------------:|:--------------:|
|           5555           |               358               |      6.44      |


<br>

<hr>
Flaky Tests - Transition Failure Rates (ect_transition.py)
<hr>

~~~python
import csv
import logging

import pdb

from sqlalchemy import Column, String, Integer, DateTime
from sqlalchemy.ext.declarative import declarative_base

from sqlalchemy import create_engine

from sqlalchemy.orm import sessionmaker

from sqlalchemy import func

from datetime import datetime

from collections import defaultdict

from sys import argv


logging.basicConfig()
logging.getLogger('sqlalchemy.engine').setLevel(logging.NOTSET)

Base = declarative_base()

class Google(Base):
  __tablename__ = 'google_dataset'
  id = Column(Integer, primary_key = True)
  test_suite_name = Column(String(2**11), nullable = False)
  test_suite_mapped_id = Column(String(2**7), nullable = False)
  change_request = Column(Integer, nullable = False)
  stage = Column(String(2**7), index = True, nullable = False)
  test_status = Column(String(2**7), index = True, nullable = False)
  launch_time = Column(DateTime, nullable = False)
  execution_time = Column(Integer, nullable = False)
  test_size = Column(String(2**7), index = True, nullable = False)
  shard_number = Column(Integer, nullable = False)
  run_number = Column(Integer, nullable = False)
  test_language = Column(String(2**7), index = True, nullable = False)

  def __init__(self, test_suite_name, test_suite_mapped_id, change_request, stage, test_status, launch_time, execution_time, test_size, shard_number, run_number, test_language):
    self.test_suite_name = test_suite_name
    self.test_suite_mapped_id = test_suite_mapped_id
    self.change_request = change_request
    self.stage = stage
    self.test_status = test_status
    self.launch_time = launch_time
    self.execution_time = execution_time
    self.test_size = test_size
    self.shard_number = shard_number
    self.run_number = run_number
    self.test_language = test_language

  def __repr__(self):
    return "<Google(mapped_id='%s', change_request='%d', shard_number='%d', status='%s', launch_time='%s', execution_time='%d', test_size='%s', test_language='%s')>" \
    % (self.test_suite_mapped_id, self.change_request, self.shard_number, self.test_status, self.launch_time, self.execution_time, self.test_size, self.test_language)

# engine = create_engine('mysql+pymysql://rkrasniq@cse.unl.edu/rkrasniq?passwd=ob8{i5&')
engine = create_engine('mysql+pymysql://root@127.0.0.1/google?passwd=sunset820&')
Session = sessionmaker(bind=engine)
session = Session()
Base.metadata.create_all(engine)

# date_object = datetime.strptime('31:00:00:02', '%m:%H:%M:%S')
# print str(date_object)

# myobject = Google('ts1', 1, 'post', 'failed', date_object, 1111, 'large', 222, 333, 'py')

def import_csv(file):
  mapped_id = defaultdict(lambda: "") 
  idx = 1

  with open(argv[1], 'rb') as csvfile:
    data = csv.reader(csvfile, delimiter=',') 
    for row in data:
      try:      
        test_suite_name = row[0]
        if mapped_id[test_suite_name] == "":
          mapped_id[test_suite_name] = "T" + str(idx)
          idx+=1
          test_suite_mapped_id = mapped_id[test_suite_name]
        else:
          test_suite_mapped_id = mapped_id[test_suite_name]
        change_request = int(row[1])
        stage = row[2].upper()
        test_status = row[3].upper()    
        launch_time = datetime.strptime(row[4], '%d:%H:%M:%S')
        execution_time = int(row[5])
        test_size = row[6].upper()
        shard_number = int(row[7])
        run_number = int(row[8])
        test_language = row[9].upper()          

        session.add(Google(test_suite_name, test_suite_mapped_id, change_request, stage, test_status, launch_time, execution_time, test_size, shard_number, run_number, test_language)) 
        session.commit()      

      except ValueError:      
        print str(row)

  csvfile.close()       


# flaky_query = "SELECT * FROM google_dataset WHERE stage=\"POST\" GROUP BY test_suite_mapped_id, change_request, shard_number ORDER BY test_suite_mapped_id, change_request,shard_number ASC"
# session.query(Google).from_statement(flaky_query).all()

data = session.query(Google).filter(Google.stage == "POST") \
.order_by(Google.test_suite_mapped_id.asc(), Google.change_request.asc(), Google.shard_number.asc()) \
.all()
# .group_by(Google.test_suite_mapped_id, Google.change_request, Google.shard_number) \

prev = data[0]

f_to_p = 0
f_to_f = 0
p_to_f = 0
p_to_p = 0

trans_change_dict = defaultdict(lambda: [])
for curr in data[1:]:
  if curr.test_suite_mapped_id == prev.test_suite_mapped_id and curr.change_request == prev.change_request:
    # trans_change_dict[curr.test_suite_mapped_id].append(curr.change_request)
    if curr.test_status != prev.test_status:
      if prev.test_status == "FAILED":      
        f_to_p += 1             
      else:
        p_to_f += 1
    else:
      if prev.test_status == "FAILED":
        f_to_f += 1
      else:
        p_to_p += 1 
  elif curr.test_suite_mapped_id == prev.test_suite_mapped_id and curr.change_request != prev.change_request:   
    trans_change_dict[curr.test_suite_mapped_id].append((prev.change_request, (f_to_p, f_to_f, p_to_f, p_to_p)))

    f_to_p = 0
    f_to_f = 0
    p_to_f = 0
    p_to_p = 0
  else:
    f_to_p = 0
    f_to_f = 0
    p_to_f = 0
    p_to_p = 0


  prev = curr
print "Test Suite\tChange Request\tF->P\tF->F\tP->F\tP->P"
for key in trans_change_dict.keys():
  for entry in trans_change_dict[key]:  
    total = float(entry[1][0] + entry[1][1] + entry[1][2] + entry[1][3]) / 100
    if total != 0:
      print "%s\t%d\t%f\t%f\t%f\t%f\t" % (key, entry[0], entry[1][0] / total, entry[1][1] / total, entry[1][2] / total, entry[1][3] / total)
    else:
      print "%s\t%d\t%f\t%f\t%f\t%f\t" % (key, entry[0], 0.0, 0.0, 0.0, 0.0) 
# for key in trans_change_dict.keys():
#   print key + "\t" + str(trans_change_dict[key])
~~~


:bulb: **Note:** For same test suite and change request the transition was calculated


<hr>

:small_red_triangle_down: Python Results for **ECT (POST)** Transitons:


|   AVG Percent  |  F-->P  |   F-->F  |   P-->F   |    P-->P   |
|:--------------:|:--------:|:--------:|:--------:|:----------:|
|   **(%)**      |  0.0483 |   0.0491 |  0.0435   |   54.21    |



:small_red_triangle_down: Python Results for **ICT (PRES)** Transitons:


|   AVG Percent  |  F-->P   |    F-->F  |   P-->F     |    P-->P   |
|:--------------:|:--------:|:---------:|:-----------:|:----------:|
|   **(%)**      |  0.0410  |   0.0240  |   0.0420    |    73.02   |



<hr>
:copyright: Rrezarta Krasniqi - University of Nebraska - Lincoln